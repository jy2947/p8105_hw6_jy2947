---
title: "p8105_hw6"
author: "Jiawei Ye"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
```
###Problem 1

This problem focuses on the homicide data gathered by Washington Post. 

Some tidying includes the new `city_state` variable, binary variable `solve_bi` with 0 for unsolved and 1 for solved. Omitted the four cities, modified the `victim_race`, and ensured `victim_age` is numeric. When the race of a victim is unknown, it is considered "non white".    
```{r load_and_tidy}
homi = read.csv("./data/homicide-data.csv") %>% 
  unite(city, state, col = "city_state", sep = ", ") %>% 
  mutate(solve_bi = 
           ifelse(disposition %in% c("Closed without arrest", "Open/No arrest"), 0, 1)) %>% 
  filter(city_state != "Dallas, TX" & city_state != "Phoenix, AZ" &
         city_state != "Kansas City, MO" & city_state != "Tulsa, AL") %>% 
  mutate(victim_race = ifelse(victim_race == "White", "white", "non-white"), 
         victim_race = as.factor(victim_race), 
         victim_race = relevel(victim_race, "white"), 
         victim_age = as.numeric(victim_age),
         city_state = as.factor(city_state))
```

The logistic regression.

```{r logi}
homi_log_fit = 
  homi %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solve_bi ~ victim_age + victim_sex + victim_race, data = .)

homi_log_fit %>% broom::tidy()
```

OR for solving homicides comparing non-white victims to white victims keeping all other variables fixed.  
And CI
```{r or}
homi_log_fit %>% 
  broom::tidy() %>% 
  mutate(or_estimate = exp(estimate), 
         ci_low = exp(estimate - 1.96 * std.error),
         ci_high = exp(estimate + 1.96 * std.error)) %>% 
  select(term, or_estimate, ci_low, ci_high) %>% 
  filter(term == "victim_racenon-white")
```

OR for every city.  
There is unreasonable value for `victim_sex` variable, which is "Pittsburg". This observation is dropped from the data, but unknown victim gender is not removed.   
```{r or_all}
glm_ci = function(df){
  glm(solve_bi ~ victim_age + victim_sex + victim_race, data = df) %>% 
  broom::tidy() %>% 
  mutate(or_estimate = round(exp(estimate), digits = 3), 
         ci_low = round(exp(estimate - 1.96 * std.error), digits = 3),
         ci_high = round(exp(estimate + 1.96 * std.error), digits = 3)) %>% 
  select(term, or_estimate, ci_low, ci_high) %>% 
  filter(term == "victim_racenon-white")
}

homi_nest = homi %>%
  select(city_state, solve_bi, victim_age, victim_sex, victim_race) %>%
  filter(victim_sex %in% c("Female", "Male", "Unknown")) %>% 
  nest(solve_bi:victim_race, .key = data) %>% 
  mutate(glm = map(data,  glm_ci)) %>% 
  select(city_state, glm) %>% 
  unnest()
```

And the plot.  
```{r set_plot, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.width = 8,
                      fig.height = 10)
```

```{r plot}
homi_nest %>% 
  ggplot(aes(x = fct_reorder(city_state, or_estimate), y = or_estimate)) +
  geom_point(color = "light blue", size = 2) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high)) +
  coord_flip() +
  labs(title = "Esitmated OR in the US with confidence intervals", 
       x = "City", 
       y = "Esitmated OR") +
  theme_classic()
```


The majority of the cities has less than 1 OR for solving homicides comparing non-white victims to white victims keeping all other variables fixed. However many of these cities have CIs that includes 1.0, indicating not statistically significant results. Some cities such as Tampa, Durham has OR larger than 1, but their CIs included 1, indicating not statistically significant results.  

#####Problem 2

Load data. Convert variables for baby sex, father race, malformation, mother race to factor variables. 
```{r load_2}
birth = read.csv("./data/birthweight.csv")
str(birth)
sum(is.na(birth))
birth = birth %>% 
  mutate(babysex = as.factor(babysex), 
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace)) 

```
The code shows that the data set do not contain missing values.  
```{r set_plot_2, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.width = 8,
                      fig.height = 6)
```

Let's see how the data looks like

```{r explore_model}
birth %>% 
  group_by(bwt) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(x = bwt, y = n)) +
  geom_point()

birth %>% 
  ggplot(aes(x = bhead, y = bwt)) +
  geom_point(alpha = .5)
  
expl_model = 
  lm(bwt ~ bhead + blength + babysex  + frace + mrace + wtgain, data = birth) 
```

Not too surprisingly, birth weight looks normal. Seems like there's some relationship between head circumference and birth weight. Also I think the race the parents, gender of the baby, mother's weight gain are associated with baby's birth weight.Therefore I build a model as above.  

```{r resi_fit}
birth %>% 
  add_predictions(expl_model) %>% 
  add_residuals(expl_model) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5, color = "blue") +
  theme_bw()
```
There are some outliers for the under weight newborns, but for the fitted values around 3 kilograms, the residuals are more or less evenly distributed around 0 line, but not really perfect. 

Other specified models.  
```{r other_models}
ges_model = lm(bwt ~ blength + gaweeks, data = birth)
interaction_model = lm(bwt ~ bhead + blength + babysex +
                             bhead * blength + bhead * babysex + blength * babysex + 
                             bhead * blength * babysex, 
                             data = birth)
```

Compare the models.  
```{r compare}
cv_df = crossv_mc(birth, 100)
cv_df = cv_df %>% 
  mutate(expl_m  = map(train, ~lm(bwt ~ bhead + blength + babysex  + frace + mrace + wtgain, data = .x)), 
         ges_m   = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
         inter_m = map(train, ~lm(bwt ~ bhead + blength + babysex +
                                        bhead * blength + bhead * babysex + blength * babysex + 
                                        bhead * blength * babysex, data = .x))) %>% 
  mutate(rmse_expl  = map2_dbl(expl_m, test, ~rmse(model = .x, data = .y)), 
         rmse_ges   = map2_dbl(ges_m, test, ~rmse(model = .x, data = .y)),
         rmse_inter = map2_dbl(inter_m, test, ~rmse(model = .x, data = .y)))

  
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  theme_bw()

```

It turns out that my model has the smallest root mean square error. My model has 6 variables and is not the best in terms of parsimony. The model with gestational age in weeks and length at birth has a rather high root mean square error indicating a not very good fit. The model using head circumferences, length, sex and all the interaction is a bit complicated but has aceptable goodness of fit.  